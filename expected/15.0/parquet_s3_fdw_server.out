\set ECHO none
show server_version \gset
\ir sql/:server_version/parquet_s3_fdw.sql
SET datestyle = 'ISO';
SET client_min_messages = WARNING;
SET log_statement TO 'none';
--Testcase 1:
CREATE EXTENSION parquet_s3_fdw;
--Testcase 2:
DROP ROLE IF EXISTS regress_parquet_s3_fdw;
--Testcase 3:
CREATE ROLE regress_parquet_s3_fdw LOGIN SUPERUSER;
SET ROLE regress_parquet_s3_fdw;
--Testcase 4:
CREATE SERVER parquet_s3_srv FOREIGN DATA WRAPPER parquet_s3_fdw :USE_MINIO;
--Testcase 5:
CREATE USER MAPPING FOR regress_parquet_s3_fdw SERVER parquet_s3_srv :USER_PASSWORD;
SET ROLE regress_parquet_s3_fdw;
\set var :PATH_FILENAME'/data/simple/example1.parquet'
--Testcase 6:
CREATE FOREIGN TABLE example1 (
    one     INT8,
    two     INT8[],
    three   TEXT,
    four    TIMESTAMP,
    five    DATE,
    six     BOOL,
    seven   FLOAT8)
SERVER parquet_s3_srv
OPTIONS (filename :'var', sorted 'one');
--Testcase 7:
SELECT * FROM example1;
 one |    two     | three |        four         |    five    | six | seven 
-----+------------+-------+---------------------+------------+-----+-------
   1 | {1,2,3}    | foo   | 2018-01-01 00:00:00 | 2018-01-01 | t   |   0.5
   2 | {NULL,5,6} | bar   | 2018-01-02 00:00:00 | 2018-01-02 | f   |      
   3 | {7,8,9}    | baz   | 2018-01-03 00:00:00 | 2018-01-03 | t   |     1
   4 | {10,11,12} | uno   | 2018-01-04 00:00:00 | 2018-01-04 | f   |   1.5
   5 | {13,14,15} | dos   | 2018-01-05 00:00:00 | 2018-01-05 | f   |      
   6 | {16,17,18} | tres  | 2018-01-06 00:00:00 | 2018-01-06 | f   |     2
(6 rows)

-- no explicit columns mentions
--Testcase 8:
SELECT 1 as x FROM example1;
 x 
---
 1
 1
 1
 1
 1
 1
(6 rows)

--Testcase 9:
SELECT count(*) as count FROM example1;
 count 
-------
     6
(1 row)

-- sorting
--Testcase 10:
EXPLAIN (COSTS OFF) SELECT * FROM example1 ORDER BY one;
        QUERY PLAN        
--------------------------
 Foreign Scan on example1
   Reader: Single File
   Row groups: 1, 2
(3 rows)

--Testcase 11:
EXPLAIN (COSTS OFF) SELECT * FROM example1 ORDER BY three;
           QUERY PLAN           
--------------------------------
 Sort
   Sort Key: three
   ->  Foreign Scan on example1
         Reader: Single File
         Row groups: 1, 2
(5 rows)

-- filtering
SET client_min_messages = DEBUG1;
--Testcase 12:
SELECT * FROM example1 WHERE one < 1;
psql:sql/15.0/parquet_s3_fdw.sql:49: DEBUG:  parquet_s3_fdw: skip rowgroup 1
psql:sql/15.0/parquet_s3_fdw.sql:49: DEBUG:  parquet_s3_fdw: skip rowgroup 2
 one | two | three | four | five | six | seven 
-----+-----+-------+------+------+-----+-------
(0 rows)

--Testcase 13:
SELECT * FROM example1 WHERE one <= 1;
psql:sql/15.0/parquet_s3_fdw.sql:51: DEBUG:  parquet_s3_fdw: skip rowgroup 2
psql:sql/15.0/parquet_s3_fdw.sql:51: DEBUG:  parquet_s3_fdw: open Parquet file on S3. datasimple/example1.parquet
 one |   two   | three |        four         |    five    | six | seven 
-----+---------+-------+---------------------+------------+-----+-------
   1 | {1,2,3} | foo   | 2018-01-01 00:00:00 | 2018-01-01 | t   |   0.5
(1 row)

--Testcase 14:
SELECT * FROM example1 WHERE one > 6;
psql:sql/15.0/parquet_s3_fdw.sql:53: DEBUG:  parquet_s3_fdw: skip rowgroup 1
psql:sql/15.0/parquet_s3_fdw.sql:53: DEBUG:  parquet_s3_fdw: skip rowgroup 2
 one | two | three | four | five | six | seven 
-----+-----+-------+------+------+-----+-------
(0 rows)

--Testcase 15:
SELECT * FROM example1 WHERE one >= 6;
psql:sql/15.0/parquet_s3_fdw.sql:55: DEBUG:  parquet_s3_fdw: skip rowgroup 1
psql:sql/15.0/parquet_s3_fdw.sql:55: DEBUG:  parquet_s3_fdw: open Parquet file on S3. datasimple/example1.parquet
 one |    two     | three |        four         |    five    | six | seven 
-----+------------+-------+---------------------+------------+-----+-------
   6 | {16,17,18} | tres  | 2018-01-06 00:00:00 | 2018-01-06 | f   |     2
(1 row)

--Testcase 16:
SELECT * FROM example1 WHERE one = 2;
psql:sql/15.0/parquet_s3_fdw.sql:57: DEBUG:  parquet_s3_fdw: skip rowgroup 2
psql:sql/15.0/parquet_s3_fdw.sql:57: DEBUG:  parquet_s3_fdw: open Parquet file on S3. datasimple/example1.parquet
 one |    two     | three |        four         |    five    | six | seven 
-----+------------+-------+---------------------+------------+-----+-------
   2 | {NULL,5,6} | bar   | 2018-01-02 00:00:00 | 2018-01-02 | f   |      
(1 row)

--Testcase 17:
SELECT * FROM example1 WHERE one = 7;
psql:sql/15.0/parquet_s3_fdw.sql:59: DEBUG:  parquet_s3_fdw: skip rowgroup 1
psql:sql/15.0/parquet_s3_fdw.sql:59: DEBUG:  parquet_s3_fdw: skip rowgroup 2
 one | two | three | four | five | six | seven 
-----+-----+-------+------+------+-----+-------
(0 rows)

--Testcase 18:
SELECT * FROM example1 WHERE six = true;
psql:sql/15.0/parquet_s3_fdw.sql:61: DEBUG:  parquet_s3_fdw: skip rowgroup 2
psql:sql/15.0/parquet_s3_fdw.sql:61: DEBUG:  parquet_s3_fdw: open Parquet file on S3. datasimple/example1.parquet
 one |   two   | three |        four         |    five    | six | seven 
-----+---------+-------+---------------------+------------+-----+-------
   1 | {1,2,3} | foo   | 2018-01-01 00:00:00 | 2018-01-01 | t   |   0.5
   3 | {7,8,9} | baz   | 2018-01-03 00:00:00 | 2018-01-03 | t   |     1
(2 rows)

--Testcase 19:
SELECT * FROM example1 WHERE six = false;
psql:sql/15.0/parquet_s3_fdw.sql:63: DEBUG:  parquet_s3_fdw: open Parquet file on S3. datasimple/example1.parquet
 one |    two     | three |        four         |    five    | six | seven 
-----+------------+-------+---------------------+------------+-----+-------
   2 | {NULL,5,6} | bar   | 2018-01-02 00:00:00 | 2018-01-02 | f   |      
   4 | {10,11,12} | uno   | 2018-01-04 00:00:00 | 2018-01-04 | f   |   1.5
   5 | {13,14,15} | dos   | 2018-01-05 00:00:00 | 2018-01-05 | f   |      
   6 | {16,17,18} | tres  | 2018-01-06 00:00:00 | 2018-01-06 | f   |     2
(4 rows)

--Testcase 20:
SELECT * FROM example1 WHERE seven < 1.5;
psql:sql/15.0/parquet_s3_fdw.sql:65: DEBUG:  parquet_s3_fdw: skip rowgroup 2
psql:sql/15.0/parquet_s3_fdw.sql:65: DEBUG:  parquet_s3_fdw: open Parquet file on S3. datasimple/example1.parquet
 one |   two   | three |        four         |    five    | six | seven 
-----+---------+-------+---------------------+------------+-----+-------
   1 | {1,2,3} | foo   | 2018-01-01 00:00:00 | 2018-01-01 | t   |   0.5
   3 | {7,8,9} | baz   | 2018-01-03 00:00:00 | 2018-01-03 | t   |     1
(2 rows)

--Testcase 21:
SELECT * FROM example1 WHERE seven <= 1.5;
psql:sql/15.0/parquet_s3_fdw.sql:67: DEBUG:  parquet_s3_fdw: open Parquet file on S3. datasimple/example1.parquet
 one |    two     | three |        four         |    five    | six | seven 
-----+------------+-------+---------------------+------------+-----+-------
   1 | {1,2,3}    | foo   | 2018-01-01 00:00:00 | 2018-01-01 | t   |   0.5
   3 | {7,8,9}    | baz   | 2018-01-03 00:00:00 | 2018-01-03 | t   |     1
   4 | {10,11,12} | uno   | 2018-01-04 00:00:00 | 2018-01-04 | f   |   1.5
(3 rows)

--Testcase 22:
SELECT * FROM example1 WHERE seven = 1.5;
psql:sql/15.0/parquet_s3_fdw.sql:69: DEBUG:  parquet_s3_fdw: skip rowgroup 1
psql:sql/15.0/parquet_s3_fdw.sql:69: DEBUG:  parquet_s3_fdw: open Parquet file on S3. datasimple/example1.parquet
 one |    two     | three |        four         |    five    | six | seven 
-----+------------+-------+---------------------+------------+-----+-------
   4 | {10,11,12} | uno   | 2018-01-04 00:00:00 | 2018-01-04 | f   |   1.5
(1 row)

--Testcase 23:
SELECT * FROM example1 WHERE seven > 1;
psql:sql/15.0/parquet_s3_fdw.sql:71: DEBUG:  parquet_s3_fdw: skip rowgroup 1
psql:sql/15.0/parquet_s3_fdw.sql:71: DEBUG:  parquet_s3_fdw: open Parquet file on S3. datasimple/example1.parquet
 one |    two     | three |        four         |    five    | six | seven 
-----+------------+-------+---------------------+------------+-----+-------
   4 | {10,11,12} | uno   | 2018-01-04 00:00:00 | 2018-01-04 | f   |   1.5
   6 | {16,17,18} | tres  | 2018-01-06 00:00:00 | 2018-01-06 | f   |     2
(2 rows)

--Testcase 24:
SELECT * FROM example1 WHERE seven >= 1;
psql:sql/15.0/parquet_s3_fdw.sql:73: DEBUG:  parquet_s3_fdw: open Parquet file on S3. datasimple/example1.parquet
 one |    two     | three |        four         |    five    | six | seven 
-----+------------+-------+---------------------+------------+-----+-------
   3 | {7,8,9}    | baz   | 2018-01-03 00:00:00 | 2018-01-03 | t   |     1
   4 | {10,11,12} | uno   | 2018-01-04 00:00:00 | 2018-01-04 | f   |   1.5
   6 | {16,17,18} | tres  | 2018-01-06 00:00:00 | 2018-01-06 | f   |     2
(3 rows)

--Testcase 25:
SELECT * FROM example1 WHERE seven IS NULL;
psql:sql/15.0/parquet_s3_fdw.sql:75: DEBUG:  parquet_s3_fdw: open Parquet file on S3. datasimple/example1.parquet
 one |    two     | three |        four         |    five    | six | seven 
-----+------------+-------+---------------------+------------+-----+-------
   2 | {NULL,5,6} | bar   | 2018-01-02 00:00:00 | 2018-01-02 | f   |      
   5 | {13,14,15} | dos   | 2018-01-05 00:00:00 | 2018-01-05 | f   |      
(2 rows)

-- prepared statements
--Testcase 26:
prepare prep(date) as select * from example1 where five < $1;
--Testcase 27:
execute prep('2018-01-03');
psql:sql/15.0/parquet_s3_fdw.sql:81: DEBUG:  parquet_s3_fdw: skip rowgroup 2
psql:sql/15.0/parquet_s3_fdw.sql:81: DEBUG:  parquet_s3_fdw: open Parquet file on S3. datasimple/example1.parquet
 one |    two     | three |        four         |    five    | six | seven 
-----+------------+-------+---------------------+------------+-----+-------
   1 | {1,2,3}    | foo   | 2018-01-01 00:00:00 | 2018-01-01 | t   |   0.5
   2 | {NULL,5,6} | bar   | 2018-01-02 00:00:00 | 2018-01-02 | f   |      
(2 rows)

--Testcase 28:
execute prep('2018-01-01');
psql:sql/15.0/parquet_s3_fdw.sql:83: DEBUG:  parquet_s3_fdw: skip rowgroup 1
psql:sql/15.0/parquet_s3_fdw.sql:83: DEBUG:  parquet_s3_fdw: skip rowgroup 2
 one | two | three | four | five | six | seven 
-----+-----+-------+------+------+-----+-------
(0 rows)

-- invalid options
SET client_min_messages = WARNING;
--Testcase 29:
CREATE FOREIGN TABLE example_fail (one INT8, two INT8[], three TEXT)
SERVER parquet_s3_srv;
psql:sql/15.0/parquet_s3_fdw.sql:89: ERROR:  parquet_s3_fdw: filename or function is required
--Testcase 30:
CREATE FOREIGN TABLE example_fail (one INT8, two INT8[], three TEXT)
SERVER parquet_s3_srv
OPTIONS (filename 'nonexistent.parquet', some_option '123');
psql:sql/15.0/parquet_s3_fdw.sql:93: ERROR:  parquet_s3_fdw: No such file or directory ('nonexistent.parquet')
\set var :PATH_FILENAME'/data/simple/example1.parquet'
--Testcase 31:
CREATE FOREIGN TABLE example_fail (one INT8, two INT8[], three TEXT)
SERVER parquet_s3_srv
OPTIONS (filename :'var', some_option '123');
psql:sql/15.0/parquet_s3_fdw.sql:98: ERROR:  parquet_s3_fdw: invalid option "some_option"
-- type mismatch
\set var :PATH_FILENAME'/data/simple/example1.parquet'
--Testcase 32:
CREATE FOREIGN TABLE example_fail (one INT8[], two INT8, three TEXT)
SERVER parquet_s3_srv
OPTIONS (filename :'var', sorted 'one');
--Testcase 33:
SELECT one FROM example_fail;
psql:sql/15.0/parquet_s3_fdw.sql:107: ERROR:  parquet_s3_fdw: failed to initialize cast function for column 'one' (parquet_s3_fdw: coercion pathway from 'bigint' to 'bigint[]' not found)
--Testcase 34:
SELECT two FROM example_fail;
psql:sql/15.0/parquet_s3_fdw.sql:109: ERROR:  parquet_s3_fdw: cannot convert parquet column of type LIST to scalar type of postgres column 'two'
-- files_func
--Testcase 35:
CREATE FUNCTION list_parquet_s3_files(args JSONB)
RETURNS TEXT[] AS
$$
    SELECT ARRAY[args->>'dir' || '/example1.parquet', args->>'dir' || '/example2.parquet']::TEXT[];
$$
LANGUAGE SQL;
\set var '{"dir": "':PATH_FILENAME'/data/simple"}'
--Testcase 36:
CREATE FOREIGN TABLE example_func (one INT8, two INT8[], three TEXT)
SERVER parquet_s3_srv
OPTIONS (
    files_func 'list_parquet_s3_files',
    files_func_arg :'var',
    sorted 'one');
--Testcase 37:
SELECT * FROM example_func;
 one |    two     | three 
-----+------------+-------
   1 | {1,2,3}    | foo
   2 | {NULL,5,6} | bar
   3 | {7,8,9}    | baz
   4 | {10,11,12} | uno
   5 | {13,14,15} | dos
   6 | {16,17,18} | tres
   1 | {19,20}    | eins
   3 | {21,22}    | zwei
   5 | {23,24}    | drei
   7 | {25,26}    | vier
   9 | {27,28}    | f端nf
(11 rows)

-- invalid files_func options
--Testcase 38:
CREATE FUNCTION int_array_func(args JSONB)
RETURNS INT[] AS
$$ SELECT ARRAY[1,2,3]::INT[]; $$
LANGUAGE SQL;
--Testcase 39:
CREATE FUNCTION no_args_func()
RETURNS TEXT[] AS
$$ SELECT ARRAY['s3://data/simple/example1.parquet']::TEXT[]; $$
LANGUAGE SQL;
--Testcase 40:
CREATE FOREIGN TABLE example_inv_func (one INT8, two INT8[], three TEXT)
SERVER parquet_s3_srv
OPTIONS (files_func 'int_array_func');
psql:sql/15.0/parquet_s3_fdw.sql:144: ERROR:  parquet_s3_fdw: return type of 'int_array_func' is integer[]; expected text[]
--Testcase 41:
CREATE FOREIGN TABLE example_inv_func (one INT8, two INT8[], three TEXT)
SERVER parquet_s3_srv
OPTIONS (files_func 'no_args_func');
psql:sql/15.0/parquet_s3_fdw.sql:148: ERROR:  function no_args_func(jsonb) does not exist
--Testcase 42:
CREATE FOREIGN TABLE example_inv_func (one INT8, two INT8[], three TEXT)
SERVER parquet_s3_srv
OPTIONS (files_func 'list_parquet_s3_files', files_func_arg 'invalid json');
psql:sql/15.0/parquet_s3_fdw.sql:152: ERROR:  invalid input syntax for type json
DETAIL:  Token "invalid" is invalid.
CONTEXT:  JSON data, line 1: invalid...
--Testcase 43:
DROP FUNCTION list_parquet_s3_files(JSONB);
--Testcase 44:
DROP FUNCTION int_array_func(JSONB);
--Testcase 45:
DROP FUNCTION no_args_func();
-- sequential multifile reader
\set var :PATH_FILENAME'/data/simple/example1.parquet ':PATH_FILENAME'/data/simple/example2.parquet'
--Testcase 46:
CREATE FOREIGN TABLE example_seq (
    one     INT8,
    two     INT8[],
    three   TEXT,
    four    TIMESTAMP,
    five    DATE,
    six     BOOL,
    seven   FLOAT8)
SERVER parquet_s3_srv
OPTIONS (filename :'var');
--Testcase 47:
EXPLAIN (COSTS OFF) SELECT * FROM example_seq;
         QUERY PLAN          
-----------------------------
 Foreign Scan on example_seq
   Reader: Multifile
   Row groups: 
     example1.parquet: 1, 2
     example2.parquet: 1
(5 rows)

--Testcase 48:
SELECT * FROM example_seq;
 one |    two     | three |        four         |    five    | six | seven 
-----+------------+-------+---------------------+------------+-----+-------
   1 | {1,2,3}    | foo   | 2018-01-01 00:00:00 | 2018-01-01 | t   |   0.5
   2 | {NULL,5,6} | bar   | 2018-01-02 00:00:00 | 2018-01-02 | f   |      
   3 | {7,8,9}    | baz   | 2018-01-03 00:00:00 | 2018-01-03 | t   |     1
   4 | {10,11,12} | uno   | 2018-01-04 00:00:00 | 2018-01-04 | f   |   1.5
   5 | {13,14,15} | dos   | 2018-01-05 00:00:00 | 2018-01-05 | f   |      
   6 | {16,17,18} | tres  | 2018-01-06 00:00:00 | 2018-01-06 | f   |     2
   1 | {19,20}    | eins  | 2018-01-01 00:00:00 | 2018-01-01 | t   |      
   3 | {21,22}    | zwei  | 2018-01-03 00:00:00 | 2018-01-03 | f   |      
   5 | {23,24}    | drei  | 2018-01-05 00:00:00 | 2018-01-05 | t   |      
   7 | {25,26}    | vier  | 2018-01-07 00:00:00 | 2018-01-07 | f   |      
   9 | {27,28}    | f端nf  | 2018-01-09 00:00:00 | 2018-01-09 | t   |      
(11 rows)

-- multifile merge reader
\set var :PATH_FILENAME'/data/simple/example1.parquet ':PATH_FILENAME'/data/simple/example2.parquet'
--Testcase 49:
CREATE FOREIGN TABLE example_sorted (
    one     INT8,
    two     INT8[],
    three   TEXT,
    four    TIMESTAMP,
    five    DATE,
    six     BOOL,
    seven   FLOAT8)
SERVER parquet_s3_srv
OPTIONS (filename :'var', sorted 'one');
--Testcase 50:
EXPLAIN (COSTS OFF) SELECT * FROM example_sorted ORDER BY one;
           QUERY PLAN           
--------------------------------
 Foreign Scan on example_sorted
   Reader: Multifile Merge
   Row groups: 
     example1.parquet: 1, 2
     example2.parquet: 1
(5 rows)

--Testcase 51:
SELECT * FROM example_sorted ORDER BY one;
 one |    two     | three |        four         |    five    | six | seven 
-----+------------+-------+---------------------+------------+-----+-------
   1 | {1,2,3}    | foo   | 2018-01-01 00:00:00 | 2018-01-01 | t   |   0.5
   1 | {19,20}    | eins  | 2018-01-01 00:00:00 | 2018-01-01 | t   |      
   2 | {NULL,5,6} | bar   | 2018-01-02 00:00:00 | 2018-01-02 | f   |      
   3 | {7,8,9}    | baz   | 2018-01-03 00:00:00 | 2018-01-03 | t   |     1
   3 | {21,22}    | zwei  | 2018-01-03 00:00:00 | 2018-01-03 | f   |      
   4 | {10,11,12} | uno   | 2018-01-04 00:00:00 | 2018-01-04 | f   |   1.5
   5 | {13,14,15} | dos   | 2018-01-05 00:00:00 | 2018-01-05 | f   |      
   5 | {23,24}    | drei  | 2018-01-05 00:00:00 | 2018-01-05 | t   |      
   6 | {16,17,18} | tres  | 2018-01-06 00:00:00 | 2018-01-06 | f   |     2
   7 | {25,26}    | vier  | 2018-01-07 00:00:00 | 2018-01-07 | f   |      
   9 | {27,28}    | f端nf  | 2018-01-09 00:00:00 | 2018-01-09 | t   |      
(11 rows)

-- caching multifile merge reader
\set var :PATH_FILENAME'/data/simple/example1.parquet ':PATH_FILENAME'/data/simple/example2.parquet'
--Testcase 52:
CREATE FOREIGN TABLE example_sorted_caching (
    one     INT8,
    two     INT8[],
    three   TEXT,
    four    TIMESTAMP,
    five    DATE,
    six     BOOL,
    seven   FLOAT8)
SERVER parquet_s3_srv
OPTIONS (filename :'var', sorted 'one', max_open_files '1');
--Testcase 53:
EXPLAIN (COSTS OFF) SELECT * FROM example_sorted_caching ORDER BY one;
               QUERY PLAN               
----------------------------------------
 Foreign Scan on example_sorted_caching
   Reader: Caching Multifile Merge
   Row groups: 
     example1.parquet: 1, 2
     example2.parquet: 1
(5 rows)

--Testcase 54:
SELECT * FROM example_sorted_caching ORDER BY one;
 one |    two     | three |        four         |    five    | six | seven 
-----+------------+-------+---------------------+------------+-----+-------
   1 | {1,2,3}    | foo   | 2018-01-01 00:00:00 | 2018-01-01 | t   |   0.5
   1 | {19,20}    | eins  | 2018-01-01 00:00:00 | 2018-01-01 | t   |      
   2 | {NULL,5,6} | bar   | 2018-01-02 00:00:00 | 2018-01-02 | f   |      
   3 | {7,8,9}    | baz   | 2018-01-03 00:00:00 | 2018-01-03 | t   |     1
   3 | {21,22}    | zwei  | 2018-01-03 00:00:00 | 2018-01-03 | f   |      
   4 | {10,11,12} | uno   | 2018-01-04 00:00:00 | 2018-01-04 | f   |   1.5
   5 | {13,14,15} | dos   | 2018-01-05 00:00:00 | 2018-01-05 | f   |      
   5 | {23,24}    | drei  | 2018-01-05 00:00:00 | 2018-01-05 | t   |      
   6 | {16,17,18} | tres  | 2018-01-06 00:00:00 | 2018-01-06 | f   |     2
   7 | {25,26}    | vier  | 2018-01-07 00:00:00 | 2018-01-07 | f   |      
   9 | {27,28}    | f端nf  | 2018-01-09 00:00:00 | 2018-01-09 | t   |      
(11 rows)

-- parallel execution
SET parallel_setup_cost = 0;
SET parallel_tuple_cost = 0.001;
EXPLAIN (COSTS OFF) SELECT * FROM example_seq;
                 QUERY PLAN                 
--------------------------------------------
 Gather
   Workers Planned: 2
   ->  Parallel Foreign Scan on example_seq
         Reader: Multifile
         Row groups: 
           example1.parquet: 1, 2
           example2.parquet: 1
(7 rows)

--Testcase 56:
EXPLAIN (COSTS OFF) SELECT * FROM example_seq ORDER BY one;
                    QUERY PLAN                    
--------------------------------------------------
 Gather Merge
   Workers Planned: 2
   ->  Sort
         Sort Key: one
         ->  Parallel Foreign Scan on example_seq
               Reader: Multifile
               Row groups: 
                 example1.parquet: 1, 2
                 example2.parquet: 1
(9 rows)

--Testcase 57:
EXPLAIN (COSTS OFF) SELECT * FROM example_seq ORDER BY two;
                    QUERY PLAN                    
--------------------------------------------------
 Gather Merge
   Workers Planned: 2
   ->  Sort
         Sort Key: two
         ->  Parallel Foreign Scan on example_seq
               Reader: Multifile
               Row groups: 
                 example1.parquet: 1, 2
                 example2.parquet: 1
(9 rows)

--Testcase 58:
EXPLAIN (COSTS OFF) SELECT * FROM example_sorted;
                  QUERY PLAN                   
-----------------------------------------------
 Gather
   Workers Planned: 2
   ->  Parallel Foreign Scan on example_sorted
         Reader: Multifile
         Row groups: 
           example1.parquet: 1, 2
           example2.parquet: 1
(7 rows)

--Testcase 59:
EXPLAIN (COSTS OFF) SELECT * FROM example_sorted ORDER BY one;
                     QUERY PLAN                      
-----------------------------------------------------
 Gather Merge
   Workers Planned: 2
   ->  Sort
         Sort Key: one
         ->  Parallel Foreign Scan on example_sorted
               Reader: Multifile
               Row groups: 
                 example1.parquet: 1, 2
                 example2.parquet: 1
(9 rows)

--Testcase 60:
EXPLAIN (COSTS OFF) SELECT * FROM example_sorted ORDER BY two;
                     QUERY PLAN                      
-----------------------------------------------------
 Gather Merge
   Workers Planned: 2
   ->  Sort
         Sort Key: two
         ->  Parallel Foreign Scan on example_sorted
               Reader: Multifile
               Row groups: 
                 example1.parquet: 1, 2
                 example2.parquet: 1
(9 rows)

ALTER FOREIGN TABLE example_sorted OPTIONS (ADD files_in_order 'true');
EXPLAIN (COSTS OFF) SELECT * FROM example_sorted ORDER BY one;
                  QUERY PLAN                   
-----------------------------------------------
 Gather Merge
   Workers Planned: 2
   ->  Parallel Foreign Scan on example_sorted
         Reader: Multifile
         Row groups: 
           example1.parquet: 1, 2
           example2.parquet: 1
(7 rows)

--Testcase 61:
EXPLAIN (COSTS OFF) SELECT * FROM example1;
               QUERY PLAN                
-----------------------------------------
 Gather
   Workers Planned: 2
   ->  Parallel Foreign Scan on example1
         Reader: Single File
         Row groups: 1, 2
(5 rows)

--Testcase 62:
SELECT SUM(one) FROM example1;
 sum 
-----
  21
(1 row)

-- multiple sorting keys
\set var :PATH_FILENAME'/data/simple/example1.parquet'
--Testcase 63:
CREATE FOREIGN TABLE example_multisort (
    one     INT8,
    two     INT8[],
    three   TEXT,
    four    TIMESTAMP,
    five    DATE,
    six     BOOL)
SERVER parquet_s3_srv
OPTIONS (filename :'var', sorted 'one five');
--Testcase 64:
EXPLAIN (COSTS OFF) SELECT * FROM example_multisort ORDER BY one, five;
            QUERY PLAN             
-----------------------------------
 Foreign Scan on example_multisort
   Reader: Single File
   Row groups: 1, 2
(3 rows)

--Testcase 65:
SELECT * FROM example_multisort ORDER BY one, five;
 one |    two     | three |        four         |    five    | six 
-----+------------+-------+---------------------+------------+-----
   1 | {1,2,3}    | foo   | 2018-01-01 00:00:00 | 2018-01-01 | t
   2 | {NULL,5,6} | bar   | 2018-01-02 00:00:00 | 2018-01-02 | f
   3 | {7,8,9}    | baz   | 2018-01-03 00:00:00 | 2018-01-03 | t
   4 | {10,11,12} | uno   | 2018-01-04 00:00:00 | 2018-01-04 | f
   5 | {13,14,15} | dos   | 2018-01-05 00:00:00 | 2018-01-05 | f
   6 | {16,17,18} | tres  | 2018-01-06 00:00:00 | 2018-01-06 | f
(6 rows)

-- maps
\set var :PATH_FILENAME'/data/complex/example3.parquet'
SET client_min_messages = DEBUG1;
--Testcase 66:
CREATE FOREIGN TABLE example3 (
    one     JSONB,
    two     JSONB,
    three   INT2)
SERVER parquet_s3_srv
OPTIONS (filename :'var', sorted 'one');
--Testcase 67:
SELECT * FROM example3;
psql:sql/15.0/parquet_s3_fdw.sql:264: DEBUG:  parquet_s3_fdw: open Parquet file on S3. datacomplex/example3.parquet
psql:sql/15.0/parquet_s3_fdw.sql:264: DEBUG:  parquet_s3_fdw: open Parquet file on S3. datacomplex/example3.parquet
psql:sql/15.0/parquet_s3_fdw.sql:264: DEBUG:  parquet_s3_fdw: open Parquet file on S3. datacomplex/example3.parquet
                 one                  |                 two                  | three 
--------------------------------------+--------------------------------------+-------
 {"1": "foo", "2": "bar", "3": "baz"} | {"2018-01-01": 10, "2018-01-02": 15} |     1
 {"4": "test1", "5": "test2"}         | {"2018-01-03": 20, "2018-01-04": 25} |     2
(2 rows)

--Testcase 68:
SELECT * FROM example3 WHERE three = 3;
psql:sql/15.0/parquet_s3_fdw.sql:266: DEBUG:  parquet_s3_fdw: skip rowgroup 1
 one | two | three 
-----+-----+-------
(0 rows)

-- analyze
ANALYZE example_sorted;
psql:sql/15.0/parquet_s3_fdw.sql:269: DEBUG:  parquet_s3_fdw: open Parquet file on S3. datasimple/example1.parquet
SET client_min_messages = WARNING;
--get version
--Testcase 69:
\df parquet_s3*
                                              List of functions
 Schema |              Name              | Result data type |           Argument data types           | Type 
--------+--------------------------------+------------------+-----------------------------------------+------
 public | parquet_s3_fdw_disconnect      | boolean          | text                                    | func
 public | parquet_s3_fdw_disconnect_all  | boolean          |                                         | func
 public | parquet_s3_fdw_get_connections | SETOF record     | OUT server_name text, OUT valid boolean | func
 public | parquet_s3_fdw_handler         | fdw_handler      |                                         | func
 public | parquet_s3_fdw_validator       | void             | text[], oid                             | func
 public | parquet_s3_fdw_version         | integer          |                                         | func
(6 rows)

--Testcase 70:
SELECT * FROM public.parquet_s3_fdw_version();
 parquet_s3_fdw_version 
------------------------
                  10000
(1 row)

--Testcase 71:
SELECT parquet_s3_fdw_version();
 parquet_s3_fdw_version 
------------------------
                  10000
(1 row)

--Testcase 72:
DROP EXTENSION parquet_s3_fdw CASCADE;
